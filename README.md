# Proyecto de Pruebas de Modelos Locales

Este es simplemente un proyecto personal para correr modelos de manera local.

Mi GPU es una RTX 3070 y un i5 14600kf, asi que están optimizados para correr con esa configuración.

Principales conclusiones: Es mucho mejor correr un modelo de manera remota ya sea con un endpoint de una API que correrlo de manera local, es bastante costoso,
consume muchos recursos y no da respuestas muy concretas, sin embargo, fue un experimento importante sobre todo jugar con los tokens, la optimización,
la temperatura y los top_p y top_k.# LLMsLocal
# LLMsLocal
# LocalLLM
# LocalLLM
# LocalLLM
